{
  "timestamp": "2025-11-18T12:39:34.233165",
  "system_info": {
    "cpu_count": 32,
    "total_ram_gb": 125.71,
    "available_ram_gb": 51.11,
    "python_version": "3.13.9 (tags/v3.13.9:8183fa5, Oct 14 2025, 14:09:13) [MSC v.1944 64 bit (AMD64)]",
    "pytorch_version": "2.9.1+cpu",
    "cuda_available": false
  },
  "models": {
    "meta-llama/Llama-3.1-70B-Instruct": {
      "model_name": "meta-llama/Llama-3.1-70B-Instruct",
      "test_mode": false,
      "status": "success",
      "error": null,
      "loading_time_seconds": 2411.49,
      "memory_before": {
        "system_ram_used_gb": 74.6,
        "system_ram_available_gb": 51.11,
        "system_ram_percent": 59.3
      },
      "memory_after": {
        "system_ram_used_gb": 82.77,
        "system_ram_available_gb": 42.94,
        "system_ram_percent": 65.8
      },
      "memory_delta": {
        "system_ram_used_gb": 8.17,
        "system_ram_available_gb": -8.17,
        "system_ram_percent": 6.5
      },
      "model_info": {
        "name": "meta-llama/Llama-3.1-70B-Instruct",
        "size": "large",
        "backend": "huggingface",
        "device_map": null,
        "torch_dtype": "torch.float16",
        "parameters": "36.3B"
      },
      "quantization": "unknown",
      "generation_test": "passed"
    },
    "Qwen/Qwen-2.5-Omni-7B": {
      "model_name": "Qwen/Qwen-2.5-Omni-7B",
      "test_mode": false,
      "status": "success",
      "error": null,
      "loading_time_seconds": 31.91,
      "memory_before": {
        "system_ram_used_gb": 111.31,
        "system_ram_available_gb": 14.4,
        "system_ram_percent": 88.5
      },
      "memory_after": {
        "system_ram_used_gb": 116.99,
        "system_ram_available_gb": 8.72,
        "system_ram_percent": 93.1
      },
      "memory_delta": {
        "system_ram_used_gb": 5.68,
        "system_ram_available_gb": -5.68,
        "system_ram_percent": 4.6
      },
      "model_info": {
        "name": "Qwen/Qwen2.5-Omni-7B",
        "size": "small",
        "backend": "huggingface",
        "device_map": null,
        "torch_dtype": "torch.float16",
        "parameters": "10.7B"
      },
      "quantization": "unknown",
      "generation_test": "failed",
      "generation_error": "argument 'ids': 'list' object cannot be interpreted as an integer"
    },
    "mistralai/Mixtral-8x22B-Instruct-v0.1": {
      "model_name": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "test_mode": false,
      "status": "failed",
      "error": "Insufficient resources for model mistralai/Mixtral-8x22B-Instruct-v0.1",
      "loading_time_seconds": null,
      "memory_before": {
        "system_ram_used_gb": 109.34,
        "system_ram_available_gb": 16.37,
        "system_ram_percent": 87.0
      },
      "memory_after": null,
      "memory_delta": null,
      "model_info": null,
      "quantization": null
    }
  }
}